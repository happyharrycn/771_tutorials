{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa489a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# helper function for image IO\n",
    "def load_image(path):\n",
    "  # load an image into RGB format\n",
    "  img = cv2.imread(path)\n",
    "  img = img[:, :, ::-1]  # BGR -> RGB\n",
    "  return img\n",
    "\n",
    "def save_image(path, img):\n",
    "  # save an RGB image into a file\n",
    "  img = img.copy()[:,:,::-1]\n",
    "  return cv2.imwrite(path, img)\n",
    "\n",
    "def resize_image(img, new_size, interpolation):\n",
    "    # resize an image into new_size (w * h) using specified interpolation\n",
    "    # opencv has a weird rounding issue & this is a hacky fix\n",
    "    # ref: https://github.com/opencv/opencv/issues/9096\n",
    "    mapping_dict = {cv2.INTER_NEAREST: Image.NEAREST}\n",
    "    if interpolation in mapping_dict:\n",
    "        pil_img = Image.fromarray(img)\n",
    "        pil_img = pil_img.resize(\n",
    "            new_size,\n",
    "            resample=mapping_dict[interpolation]\n",
    "        )\n",
    "        img = np.array(pil_img)\n",
    "    else:\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            new_size,\n",
    "            interpolation=interpolation\n",
    "        )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple dataset\n",
    "class SimpleDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple dataset using PyTorch dataloader\n",
    "    \"\"\"\n",
    "    def __init__(self, root_folder, file_ext, transforms=None):\n",
    "        # root folder, split\n",
    "        self.root_folder = root_folder\n",
    "        self.transforms = transforms\n",
    "        self.file_ext = file_ext\n",
    "\n",
    "        # load all labels\n",
    "        file_list = glob.glob(os.path.join(root_folder, '*.{:s}'.format(file_ext)))\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load img and label (from file name)\n",
    "        filename = self.file_list[index]\n",
    "        img = load_image(filename).astype(np.float32) / 255.0\n",
    "        label = os.path.basename(filename)\n",
    "        label = label.rstrip('.{:s}'.format(self.file_ext))\n",
    "        # apply data augmentation\n",
    "        if self.transforms is not None:\n",
    "            img  = self.transforms(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple data augmentation\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "      transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "      >>> Compose([\n",
    "      >>>     Scale(320),\n",
    "      >>>     RandomSizedCrop(224),\n",
    "      >>> ])\n",
    "    \"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = \"\"\n",
    "        for t in self.transforms:\n",
    "            repr_str += t.__repr__() + '\\n'\n",
    "        return repr_str\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert a ``numpy.ndarray`` image to tensor.\n",
    "    Converts a numpy.ndarray (H x W x C) image in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "    \"\"\"\n",
    "    def __call__(self, img):\n",
    "        assert isinstance(img, np.ndarray)\n",
    "        # convert image to tensor\n",
    "        assert (img.ndim > 1) and (img.ndim <= 3)\n",
    "        if img.ndim == 2:\n",
    "            img = img[:, :, None]\n",
    "            tensor_img = torch.from_numpy(\n",
    "                np.ascontiguousarray(img.transpose((2, 0, 1)))\n",
    "            )\n",
    "        if img.ndim == 3:\n",
    "            tensor_img = torch.from_numpy(\n",
    "                np.ascontiguousarray(img.transpose((2, 0, 1)))\n",
    "            )\n",
    "        # backward compatibility\n",
    "        if isinstance(tensor_img, torch.ByteTensor):\n",
    "            return tensor_img.float().div(255.0)\n",
    "        else:\n",
    "            return tensor_img\n",
    "\n",
    "class RandomNoise(object):\n",
    "    \"\"\"Adding random Gaussian noise to an input numpy array.\n",
    "       The noise is controlled by std.\n",
    "    \"\"\"\n",
    "    def __init__(self, std):\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        assert isinstance(img, np.ndarray)\n",
    "        noise = np.random.randn(*img.shape) * self.std\n",
    "        img = img.astype(np.float32) + noise.astype(np.float32)\n",
    "        return img\n",
    "\n",
    "class Resize(object):\n",
    "    \"\"\"Resize an input image into a fixed resolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, size):\n",
    "        assert (\n",
    "            isinstance(size, int)\n",
    "            or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "           )\n",
    "        if isinstance(size, int):\n",
    "            self.size = (size, size)\n",
    "        else:\n",
    "            self.size = size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        assert isinstance(img, np.ndarray)\n",
    "        img = resize_image(img, self.size, cv2.INTER_LINEAR)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cec0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# image IO using PyTorch dataloader\n",
    "# set up the transforms (make sure you convert numpy array to pytorch tensor)\n",
    "transforms = []\n",
    "transforms.append(Resize(224))\n",
    "transforms.append(RandomNoise(0.1))\n",
    "transforms.append(ToTensor())\n",
    "comp_transforms = Compose(transforms)\n",
    "\n",
    "# let us try a toy dataset\n",
    "dataset = SimpleDataset('./data', file_ext='bmp', transforms=comp_transforms)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# loop over the data set\n",
    "for batch_idx, (imgs, labels) in enumerate(data_loader):\n",
    "    print(imgs.shape)\n",
    "    print(labels)\n",
    "    for img_idx, img in enumerate(imgs):\n",
    "        vis_img = img.permute(1, 2, 0).numpy().clip(0.0, 1.0)\n",
    "        vis_img = (255 * vis_img).astype(np.uint8)\n",
    "        plt.figure(); plt.imshow(vis_img)\n",
    "        save_image('../results/loader_outputs_{:d}-{:d}.jpg'.format(batch_idx, img_idx), vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4dca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
